# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lu8Y8E5t-HlsDLooZnUDH49XKAYUZYEf
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from wordcloud import WordCloud

# Load the dataset
data = pd.read_csv('twitter_user_data.csv', encoding='ISO-8859-1')


# Step 1: Preprocessing - Scrub
# Handle missing values and clean data types

# Create new feature: tweet_to_retweet_ratio
data['tweet_to_retweet_ratio'] = data['tweet_count'] / (data['retweet_count'] + 1)

# Create a feature for description length
data['description_length'] = data['description'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 0)

# Keep only relevant features
data_cleaned = data[['fav_number', 'tweet_count', 'retweet_count', 'description_length', 'tweet_to_retweet_ratio', 'gender', 'profile_yn']]

# Drop rows with missing values in gender and profile_yn
data_cleaned = data_cleaned.dropna(subset=['gender', 'profile_yn'])

# Filter gender to keep 'male', 'female', and 'brand'
data_cleaned = data_cleaned[data_cleaned['gender'].isin(['male', 'female', 'brand'])]

# Encode categorical variables
label_encoder = LabelEncoder()
data_cleaned['gender_encoded'] = label_encoder.fit_transform(data_cleaned['gender'])
data_cleaned['profile_yn_encoded'] = label_encoder.fit_transform(data_cleaned['profile_yn'])

# Step 2: Exploratory Data Analysis (EDA) - Explore

# Summary statistics
print(data_cleaned.describe())

# Drop non-numeric columns for correlation matrix calculation
numeric_features = data_cleaned.drop(columns=['gender', 'profile_yn'])

# Correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(numeric_features.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()

# Distribution of Gender
sns.countplot(data_cleaned['gender'])
plt.title("Gender Distribution")
plt.show()

# Boxplot of tweet_count grouped by gender
plt.figure(figsize=(8, 6))
sns.boxplot(x='gender', y='tweet_count', data=data_cleaned)
plt.title("Tweet Count by Gender")
plt.show()

# Step 3: Modeling - Model

# Select features for modeling
features = ['fav_number', 'tweet_count', 'retweet_count', 'description_length', 'tweet_to_retweet_ratio', 'profile_yn_encoded']
X = data_cleaned[features].values
y = data_cleaned['gender_encoded'].values

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize models
log_reg = LogisticRegression(random_state=42, max_iter=1000)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
gbc = GradientBoostingClassifier(random_state=42)

# Train models
log_reg.fit(X_train_scaled, y_train)
rf.fit(X_train, y_train)
gbc.fit(X_train, y_train)


# Predict on test set
y_pred_log_reg = log_reg.predict(X_test_scaled)
y_pred_rf = rf.predict(X_test)
y_pred_gbc = gbc.predict(X_test)

# Encode categorical variables using separate LabelEncoders
label_encoder_gender = LabelEncoder()
data_cleaned['gender_encoded'] = label_encoder_gender.fit_transform(data_cleaned['gender'])

label_encoder_profile_yn = LabelEncoder()
data_cleaned['profile_yn_encoded'] = label_encoder_profile_yn.fit_transform(data_cleaned['profile_yn'])

# ... (rest of your code remains the same)

# When generating classification reports, use the correct label encoder
print("\nLogistic Regression Classification Report:")
log_reg_report = classification_report(y_test, y_pred_log_reg, target_names=label_encoder_gender.classes_)
print(log_reg_report)

print("\nRandom Forest Classification Report:")
rf_report = classification_report(y_test, y_pred_rf, target_names=label_encoder_gender.classes_)
print(rf_report)

print("\nGradient Boosting Classification Report:")
gbc_report = classification_report(y_test, y_pred_gbc, target_names=label_encoder_gender.classes_)
print(gbc_report)

# Comparison of all models based on accuracy
# Calculate accuracies for each model
log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)
rf_accuracy = accuracy_score(y_test, y_pred_rf)
gbc_accuracy = accuracy_score(y_test, y_pred_gbc)

# Print accuracies
print("Logistic Regression Accuracy:", log_reg_accuracy)
print("Random Forest Accuracy:", rf_accuracy)
print("Gradient Boosting Accuracy:", gbc_accuracy)

# Comparison of all models based on accuracy
models = ['Logistic Regression', 'Random Forest', 'Gradient Boosting']
accuracies = [log_reg_accuracy, rf_accuracy, gbc_accuracy]

# Plot the accuracies for comparison
plt.figure(figsize=(8, 6))
sns.barplot(x=models, y=accuracies, palette='viridis')
plt.title("Model Comparison: Accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Model")
plt.show()

# Step 4: Plotting Results
# Confusion Matrix - Random Forest
conf_matrix = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.title("Confusion Matrix - Random Forest")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()


# Confusion Matrix - Gradient Boosting
conf_matrix_gbc = confusion_matrix(y_test, y_pred_gbc)
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_gbc, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.title("Confusion Matrix - Gradient Boosting")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# Confusion Matrix - Logistic Regression
conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_log_reg, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.title("Confusion Matrix - Logistic Regression")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# Plotting actual vs predicted
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_rf, alpha=0.5)
plt.title('Actual vs Predicted (Random Forest)')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_gbc, alpha=0.5)
plt.title('Actual vs Predicted (Gradient Boosting)')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_log_reg, alpha=0.5)
plt.title('Actual vs Predicted (Logistic Regression)')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

# Plotting residuals (difference between actual and predicted)
residuals = y_test - y_pred_rf
plt.figure(figsize=(8, 6))
sns.histplot(residuals, kde=True)
plt.title('Residuals of Random Forest')
plt.show()

residuals_gbc = y_test - y_pred_gbc
plt.figure(figsize=(8, 6))
sns.histplot(residuals_gbc, kde=True)
plt.title('Residuals of Gradient Boosting')
plt.show()

residuals_log_reg = y_test - y_pred_log_reg
plt.figure(figsize=(8, 6))
sns.histplot(residuals_log_reg, kde=True)
plt.title('Residuals of Logistic Regression')
plt.show()






# Assuming `data_cleaned` is your cleaned dataset
# X = Features, y = Target (gender in this case)

# Replace 'gender' with 0 (male), 1 (female), 2 (brand) if necessary
data_cleaned['gender_encoded'] = data_cleaned['gender'].map({'male': 0, 'female': 1, 'brand': 2})

# Features and target variable
X = data_cleaned[['fav_number', 'tweet_count', 'retweet_count', 'description_length', 'tweet_to_retweet_ratio', 'profile_yn_encoded']]
y = data_cleaned['gender_encoded']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Standardize the data for logistic regression
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 1. Logistic Regression
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train_scaled, y_train)

# 2. Random Forest
rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
rf_clf.fit(X_train, y_train)

# 3. Gradient Boosting
gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_clf.fit(X_train, y_train)

# Get Feature Importance
def plot_feature_importance(importances, model_name, feature_names):
    feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})
    feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)

    plt.figure(figsize=(10, 6))
    sns.barplot(x='importance', y='feature', data=feature_importance_df)
    plt.title(f'Feature Importance - {model_name}')
    plt.show()

# Logistic Regression - Feature Importance (coefficients)
log_reg_importance = abs(log_reg.coef_[0])
plot_feature_importance(log_reg_importance, 'Logistic Regression', X.columns)

# Random Forest - Feature Importance
rf_importance = rf_clf.feature_importances_
plot_feature_importance(rf_importance, 'Random Forest', X.columns)

# Gradient Boosting - Feature Importance
gb_importance = gb_clf.feature_importances_
plot_feature_importance(gb_importance, 'Gradient Boosting', X.columns)

# Print classification reports for performance comparison
print("Logistic Regression Report:\n", classification_report(y_test, log_reg.predict(X_test_scaled)))
print("Random Forest Report:\n", classification_report(y_test, rf_clf.predict(X_test)))
print("Gradient Boosting Report:\n", classification_report(y_test, gb_clf.predict(X_test)))


# Suggestions based on multiple views
# 1. Brands tend to have longer descriptions and are more likely to promote external links (as seen from link color distribution).
# 2. Humans (both male and female) have more variance in tweet length, but brands tend to focus on concise tweets.
# 3. Brands have a higher tweet-to-retweet ratio, indicating more original content versus retweets.
# 4. Both human and brand profiles show high variation in favorite counts and retweets, but human profiles generally have a more balanced profile (fav_number vs. tweet_count).
# 5. Brands should consider reducing tweet lengths to match the more concise trend seen in human profiles for better engagement.

# Step 1: Preprocessing - Scrub and prepare data
data['tweet_to_retweet_ratio'] = data['tweet_count'] / (data['retweet_count'] + 1)
data['description_length'] = data['description'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 0)

# Keep only relevant features
data_cleaned = data[['fav_number', 'tweet_count', 'retweet_count', 'description_length', 'tweet_to_retweet_ratio', 'gender']]

# Drop rows with missing values in gender
data_cleaned = data_cleaned.dropna(subset=['gender'])

# Convert gender into human vs non-human categories
data_cleaned['is_human'] = data_cleaned['gender'].apply(lambda x: 'Human' if x in ['male', 'female'] else 'Non-Human')

# Step 2: Visualization

# Boxplots comparing numerical features for humans vs non-humans
features = ['fav_number', 'tweet_count', 'retweet_count', 'description_length', 'tweet_to_retweet_ratio']


# Bar plots for mean values of numerical features for humans vs non-humans
mean_values = data_cleaned.groupby('is_human')[features].mean().reset_index()
mean_values = mean_values.melt(id_vars='is_human', var_name='Feature', value_name='Mean Value')

plt.figure(figsize=(15, 8))
sns.barplot(x='Feature', y='Mean Value', hue='is_human', data=mean_values, palette='Set2')
plt.title('Mean Values of Features by Profile Type')
plt.xticks(rotation=45)
plt.show()

# Pairplot comparing feature relationships for humans vs non-humans
sns.pairplot(data_cleaned, hue='is_human', vars=features, palette='Set2')
plt.show()

