# -*- coding: utf-8 -*-
"""Copy of Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qhM1m02vN2t3MMExA2saOu6zB5zlvKeP
"""

# Importing necessary libraries
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from matplotlib import pyplot as plt

# Read from local folder
dataframe = pd.read_csv('twitter_user_data.csv',encoding='latin1')

# Data overview

dataframe.head()

# Keeping the most important columns for clustering as we need numeric values for KMeans Clustering
relevant_columns = ['tweet_count', 'retweet_count', 'fav_number', 'description', 'profile_yn',
                    'text', 'gender', 'gender:confidence']
dataset = dataframe[relevant_columns]

# After dropping some columns, here is the overview of the data
dataset

#Check Empty/Null values in the dataset.

dataset.isna().sum()

# Preprocessing data
# Delete rows where profile_yn is 'no' because the gender is null for those too
dataset = dataset[dataset['profile_yn'] != 'no']

# Drop rows where gender is 'unknown' or null (NaN)
dataset = dataset[(dataset['gender'] != 'unknown') & (dataset['gender'].notnull())]

# Only null values remain in description column which will be filled with 0 in a new feature called "description_count" which represents the lenght of descrption
dataset.isna().sum()

# Check the types of data in dataset
dataset.info()

# There are some unwanted character, url, punctuation marks etc. in dataset. Clearing the description and text
import re
import string

# Function to clean text and description column

def clean_description(text):
    if isinstance(text, str):  # Only process if it's a string else returns empty string

        # Convert all text to lowercase
        text = text.lower()

        # Remove URLs from text
        text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)

        # Remove unwanted characters like #, @, /
        text = re.sub(r'[@#\/]', '', text)

        # Remove non-ASCII characters
        text = re.sub(r'[^\x00-\x7F]+', '', text)

        # Remove punctuation
        text = text.translate(str.maketrans('', '', string.punctuation))

        # Remove extra spaces
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    else:
        return ''  # Return empty string for non-string values or NaNs

# Apply the cleaning function to the 'description' and 'text' column
dataset['description'] = dataset['description'].apply(clean_description)
dataset['text'] = dataset['text'].apply(clean_description)

# After cleaning the description and text column here is the overview
dataset.head()

# Fill missing values in 'description' column with an empty string
dataset['description'] = dataset['description'].fillna('')

# Create two new columns for description and text lengths
dataset['description_length'] = dataset['description'].apply(len)
dataset['text_length'] = dataset['text'].apply(len)


# Overview of two new features in dataset
dataset[['description', 'description_length', 'text', 'text_length']].head()

# Since we only need numberic values, we need to convert object type to numeric values. So, map 'gender' column to numerical values: male -> 0, female -> 0, brand -> 1
dataset['gender_encoded'] = dataset['gender'].map({'male': 0, 'female': 0, 'brand': 1})

# Check the transformation
print(dataset[['gender', 'gender_encoded']].head())

# Shows the count of gender
dataset['gender'].value_counts()

# Similarly, map 'profile_yn' column to numerical values: yes -> 1, no -> 0
dataset['profile_yn'] = dataset['profile_yn'].map({'yes': 1, 'no': 0})

# Check the result
print(dataset[['profile_yn']].head())

# After preprocessing, here is the overview of the dataset
dataset

# Here are the list of columns that will be used for the clustering

cluster_columns = ['tweet_count', 'retweet_count', 'fav_number', 'description_length', 'text_length', 'gender_encoded']

# Create a new dataset with those columns only
dataset2 = dataset[cluster_columns]

# This is how new dataset looks like
dataset2

# Using MinMaxScaler for standardizing the dataset

from sklearn.preprocessing import MinMaxScaler


# Initialize MinMaxScaler
scaler = MinMaxScaler()

# Fit and transform the dataset
dataset2 = scaler.fit_transform(dataset2)

# Convert the scaled data back to a DataFrame
dataset2 = pd.DataFrame(dataset2, columns=cluster_columns)

print(dataset2.head())

# Determine the optimal number of clusters using the Elbow Method
inertia = []
k_rng = range(1, 11)  # Testing for 1 to 10 clusters
for k in k_rng:
    km = KMeans(n_clusters=k, random_state=0)
    km.fit_predict(dataset2)
    inertia.append(km.inertia_)

# Plotting the Elbow graph
plt.figure(figsize=(8, 6))
plt.plot(k_rng, inertia, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal k')
plt.show()

# Fit KMeans clustering model
kmeans = KMeans(n_clusters=2)  # We can set n_clusters to 2 based on the analysis of Elbow Method
#y_predicted = kmeans.fit_predict(dataset2[['tweet_count', 'retweet_count', 'fav_number','description_length', 'text_length']])
y_predicted = kmeans.fit_predict(dataset2)
# Saving the clustering result in dataset
dataset['cluster']=y_predicted
dataset2['cluster']=y_predicted

kmeans.cluster_centers_

# Now the cluster column is added to dataset
dataset

# Evaluate the model using silhouette score
silhouette_avg = silhouette_score(dataset2, kmeans.labels_)
print(f'Silhouette Score: {silhouette_avg}')

# Perform KMeans clustering and calculate silhouette score for each gender column
genders = ['male', 'female', 'brand']
silhouette_scores = {}

for gender in genders:
    # Filter dataset by gender
    filtered_data = dataset[dataset['gender'] == gender]
    filtered_data2 = filtered_data[cluster_columns]



    # Perform KMeans clustering
    kmeans = KMeans(n_clusters=2, random_state=0).fit(filtered_data2)
    labels = kmeans.labels_

    # Calculate silhouette score
    score = silhouette_score(filtered_data2, labels)
    silhouette_scores[gender] = score

# Display silhouette scores
for gender, score in silhouette_scores.items():
    print(f'Silhouette Score for {gender}: {score}')

# Plot silhouette scores
plt.figure(figsize=(8, 6))
plt.bar(silhouette_scores.keys(), silhouette_scores.values(), color='skyblue')
plt.xlabel('Gender')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Scores for Each Gender')
plt.grid(axis='y')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Gender Distribution in each cluster
gender_distribution = dataset.groupby(['cluster', 'gender_encoded']).size().unstack(fill_value=0)

# Label Gender Human (Male and Female) and Brand for non-human profiles
gender_distribution.columns = ['Human', 'Brand']

# Create the bar plot
gender_distribution.plot(kind='bar', stacked=True, figsize=(10, 6))

# Add labels and title for the plot
plt.xlabel('Cluster')
plt.ylabel('Number of Profiles')
plt.title('Gender Distribution in Each Cluster')
plt.xticks(rotation=0)
plt.legend(title='Gender')

# Display the plot
plt.tight_layout()
plt.show()

# List of columns to be plotted
columns = ['tweet_count', 'retweet_count', 'fav_number', 'description_length', 'text_length', 'gender_encoded']

# Generate scatter plots for all possible combinations
plt.figure(figsize=(20, 20))
plot_number = 1

for i in range(len(columns)):
    for j in range(i + 1, len(columns)):
        x_col = columns[i]
        y_col = columns[j]

        plt.figure(figsize=(10, 8))

        # Scatter plot for each pair of columns
        for cluster in dataset2['cluster'].unique():
            cluster_data = dataset2[dataset2['cluster'] == cluster]
            plt.scatter(cluster_data[x_col], cluster_data[y_col], label=f'Cluster {cluster}', alpha=0.5)

        plt.xlabel(x_col)
        plt.ylabel(y_col)
        plt.title(f'Scatter Plot of {x_col} vs {y_col}')
        plt.legend()
        plt.grid(True)

        # Display the plot
        plt.show()

# All plots in 1 Frame for better analysis

# List of columns to be plotted
columns = ['tweet_count', 'retweet_count', 'fav_number', 'description_length', 'text_length', 'gender_encoded']

# Number of possible combinations of pairs of columns
num_plots = sum(1 for i in range(len(columns)) for j in range(i + 1, len(columns)))

# Create subplots: determine the number of rows and columns needed to display all plots
fig, axes = plt.subplots(nrows=num_plots // 3 + 1, ncols=3, figsize=(18, 20))

plot_number = 0

# Generate scatter plots for all possible combinations of columns
for i in range(len(columns)):
    for j in range(i + 1, len(columns)):
        x_col = columns[i]
        y_col = columns[j]

        ax = axes[plot_number // 3, plot_number % 3]

        # Scatter plot for each pair of columns
        for cluster in dataset2['cluster'].unique():
            cluster_data = dataset2[dataset2['cluster'] == cluster]
            ax.scatter(cluster_data[x_col], cluster_data[y_col], label=f'Cluster {cluster}', alpha=0.5)

        ax.set_xlabel(x_col)
        ax.set_ylabel(y_col)
        ax.set_title(f'{x_col} vs {y_col}')
        ax.legend()
        ax.grid(True)

        plot_number += 1

# Adjust layout to avoid overlapping of plots and titles
plt.tight_layout()

# Display all plots in one figure
plt.show()